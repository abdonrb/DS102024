{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso a Paso: Implementando Pytest en un Proyecto de Data Engineering\n",
    "\n",
    "En este notebook, vamos a seguir un proceso paso a paso para implementar pytest en un proyecto de Data Engineering. Veremos cómo configurar el entorno, escribir tests efectivos y ejecutarlos para verificar la calidad de nuestro código y datos.\n",
    "\n",
    "Utilizaremos nuestro dataset de ventas de productos y crearemos un pequeño proyecto que incluya funciones para procesar y validar estos datos. Luego, implementaremos tests para asegurar que estas funciones funcionen correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Configuración del Entorno\n",
    "\n",
    "Lo primero que necesitamos es asegurarnos de tener instaladas todas las bibliotecas necesarias. Para este tutorial, necesitaremos pytest, pytest-cov (para medir la cobertura de código), pandas y numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos las bibliotecas necesarias\n",
    "# !pip install pytest pytest-cov pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Estructura del Proyecto\n",
    "\n",
    "Para este tutorial, ya hemos creado una estructura de proyecto típica para Data Engineering:\n",
    "\n",
    "```\n",
    "pytest_tutorial/\n",
    "├── data/                  # Datos de ejemplo\n",
    "│   └── ventas_productos.csv\n",
    "├── notebooks/             # Jupyter notebooks para el tutorial\n",
    "├── utils/                 # Módulos de utilidades y funciones\n",
    "│   ├── __init__.py\n",
    "│   ├── data_processing.py # Funciones para procesar datos\n",
    "│   └── data_validation.py # Funciones para validar datos\n",
    "└── tests/                 # Tests de pytest\n",
    "    ├── __init__.py\n",
    "    ├── test_processing.py # Tests para funciones de procesamiento\n",
    "    └── test_validation.py # Tests para funciones de validación\n",
    "```\n",
    "\n",
    "Vamos a crear los directorios y archivos que faltan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los directorios y archivos necesarios\n",
    "# !mkdir -p ../tests\n",
    "# !touch ../utils/__init__.py\n",
    "# !touch ../tests/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Exploración del Dataset\n",
    "\n",
    "Antes de comenzar a escribir código y tests, vamos a explorar el dataset con el que trabajaremos. Esto nos ayudará a entender mejor los datos y a diseñar funciones y tests apropiados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fecha</th>\n",
       "      <th>producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>precio</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>descuento</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>Laptop HP</td>\n",
       "      <td>Electrónica</td>\n",
       "      <td>899.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>854.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>Monitor Dell</td>\n",
       "      <td>Electrónica</td>\n",
       "      <td>249.99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>499.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>Teclado Logitech</td>\n",
       "      <td>Accesorios</td>\n",
       "      <td>59.99</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>161.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Mouse Inalámbrico</td>\n",
       "      <td>Accesorios</td>\n",
       "      <td>29.99</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>149.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>Disco SSD 500GB</td>\n",
       "      <td>Almacenamiento</td>\n",
       "      <td>89.99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>152.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       fecha           producto       categoria  precio  cantidad  \\\n",
       "0   1  2023-01-05          Laptop HP     Electrónica  899.99         1   \n",
       "1   2  2023-01-10       Monitor Dell     Electrónica  249.99         2   \n",
       "2   3  2023-01-15   Teclado Logitech      Accesorios   59.99         3   \n",
       "3   4  2023-01-20  Mouse Inalámbrico      Accesorios   29.99         5   \n",
       "4   5  2023-01-25    Disco SSD 500GB  Almacenamiento   89.99         2   \n",
       "\n",
       "   descuento   total  \n",
       "0       0.05  854.99  \n",
       "1       0.00  499.98  \n",
       "2       0.10  161.97  \n",
       "3       0.00  149.95  \n",
       "4       0.15  152.98  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el dataset\n",
    "df = pd.read_csv('../data/ventas_productos.csv')\n",
    "\n",
    "# Mostramos las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         20 non-null     int64  \n",
      " 1   fecha      20 non-null     object \n",
      " 2   producto   20 non-null     object \n",
      " 3   categoria  20 non-null     object \n",
      " 4   precio     20 non-null     float64\n",
      " 5   cantidad   20 non-null     int64  \n",
      " 6   descuento  20 non-null     float64\n",
      " 7   total      20 non-null     float64\n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Información básica del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>precio</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>descuento</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.50000</td>\n",
       "      <td>178.140000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>230.452500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.91608</td>\n",
       "      <td>204.980172</td>\n",
       "      <td>1.371707</td>\n",
       "      <td>0.067862</td>\n",
       "      <td>183.257463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.75000</td>\n",
       "      <td>57.490000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.50000</td>\n",
       "      <td>89.990000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>157.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.25000</td>\n",
       "      <td>249.990000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>289.732500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>899.990000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>854.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id      precio   cantidad  descuento       total\n",
       "count  20.00000   20.000000  20.000000  20.000000   20.000000\n",
       "mean   10.50000  178.140000   2.250000   0.075000  230.452500\n",
       "std     5.91608  204.980172   1.371707   0.067862  183.257463\n",
       "min     1.00000   12.990000   1.000000   0.000000   64.950000\n",
       "25%     5.75000   57.490000   1.000000   0.000000  123.987500\n",
       "50%    10.50000   89.990000   2.000000   0.050000  157.475000\n",
       "75%    15.25000  249.990000   3.000000   0.112500  289.732500\n",
       "max    20.00000  899.990000   5.000000   0.200000  854.990000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estadísticas descriptivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Creación de Funciones de Procesamiento de Datos\n",
    "\n",
    "Ahora vamos a crear algunas funciones para procesar nuestros datos de ventas. Estas funciones estarán en el módulo `utils.data_processing`.\n",
    "\n",
    "Primero, vamos a definir las funciones que queremos implementar:\n",
    "\n",
    "1. `calcular_metricas_ventas`: Calcula métricas básicas de ventas (total, promedio, etc.)\n",
    "2. `categorizar_productos_por_precio`: Categoriza productos según su precio\n",
    "3. `calcular_tendencia_ventas`: Calcula la tendencia de ventas por mes\n",
    "\n",
    "Vamos a implementar estas funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../utils/data_processing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../utils/data_processing.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calcular_metricas_ventas(df):\n",
    "    \"\"\"Calcula métricas de ventas a partir de un DataFrame de ventas.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'precio', 'cantidad', 'descuento' y 'total'\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con métricas calculadas\n",
    "    \"\"\"\n",
    "    metricas = {\n",
    "        'total_ventas': df['total'].sum(),\n",
    "        'promedio_venta': df['total'].mean(),\n",
    "        'total_productos_vendidos': df['cantidad'].sum(),\n",
    "        'precio_promedio': df['precio'].mean(),\n",
    "        'descuento_promedio': df['descuento'].mean(),\n",
    "        'ahorro_total': (df['precio'] * df['cantidad'] * df['descuento']).sum()\n",
    "    }\n",
    "    return metricas\n",
    "\n",
    "def categorizar_productos_por_precio(df):\n",
    "    \"\"\"Categoriza productos según su precio.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columna 'precio'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame original con columna 'categoria_precio' añadida\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Evitamos modificar el DataFrame original\n",
    "    \n",
    "    # Definimos las categorías de precio\n",
    "    condiciones = [\n",
    "        (df['precio'] < 50),\n",
    "        (df['precio'] >= 50) & (df['precio'] < 100),\n",
    "        (df['precio'] >= 100) & (df['precio'] < 200),\n",
    "        (df['precio'] >= 200)\n",
    "    ]\n",
    "    categorias = ['Económico', 'Estándar', 'Premium', 'Lujo']\n",
    "    \n",
    "    # Creamos la nueva columna\n",
    "    df['categoria_precio'] = np.select(condiciones, categorias, default='Sin categoría')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calcular_tendencia_ventas(df):\n",
    "    \"\"\"Calcula la tendencia de ventas por mes.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'fecha' y 'total'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con ventas totales por mes y variación porcentual\n",
    "    \"\"\"\n",
    "    # Convertimos la columna fecha a datetime\n",
    "    df = df.copy()\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    \n",
    "    # Extraemos el mes y agrupamos\n",
    "    df['mes'] = df['fecha'].dt.to_period('M')\n",
    "    ventas_mensuales = df.groupby('mes')['total'].sum().reset_index()\n",
    "    ventas_mensuales['mes'] = ventas_mensuales['mes'].astype(str)\n",
    "    \n",
    "    # Calculamos la variación porcentual\n",
    "    ventas_mensuales['variacion_porcentual'] = ventas_mensuales['total'].pct_change() * 100\n",
    "    \n",
    "    return ventas_mensuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Creación de Funciones de Validación de Datos\n",
    "\n",
    "Ahora vamos a crear algunas funciones para validar nuestros datos. Estas funciones estarán en el módulo `utils.data_validation`.\n",
    "\n",
    "Definiremos las siguientes funciones:\n",
    "\n",
    "1. `validar_completitud`: Verifica que no haya valores nulos en las columnas requeridas\n",
    "2. `validar_tipos_datos`: Verifica que las columnas tengan los tipos de datos esperados\n",
    "3. `validar_rango_valores`: Verifica que los valores estén dentro de los rangos especificados\n",
    "\n",
    "Vamos a implementar estas funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../utils/data_validation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../utils/data_validation.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def validar_completitud(df, columnas_requeridas=None):\n",
    "    \"\"\"Valida que no haya valores nulos en las columnas requeridas.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a validar\n",
    "        columnas_requeridas: Lista de columnas a verificar. Si es None, se verifican todas.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de la validación\n",
    "    \"\"\"\n",
    "    if columnas_requeridas is None:\n",
    "        columnas_requeridas = df.columns.tolist()\n",
    "    \n",
    "    # Verificamos que todas las columnas requeridas existan\n",
    "    columnas_faltantes = [col for col in columnas_requeridas if col not in df.columns]\n",
    "    if columnas_faltantes:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Columnas faltantes: {', '.join(columnas_faltantes)}\"\n",
    "        }\n",
    "    \n",
    "    # Verificamos valores nulos\n",
    "    nulos_por_columna = {col: int(df[col].isnull().sum()) for col in columnas_requeridas}\n",
    "    tiene_nulos = any(nulos_por_columna.values())\n",
    "    \n",
    "    if tiene_nulos:\n",
    "        columnas_con_nulos = [col for col, nulos in nulos_por_columna.items() if nulos > 0]\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Valores nulos encontrados en: {', '.join(columnas_con_nulos)}\",\n",
    "            'detalle': nulos_por_columna\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'valido': True,\n",
    "        'mensaje': \"No se encontraron valores nulos en las columnas requeridas\"\n",
    "    }\n",
    "\n",
    "def validar_tipos_datos(df, tipos_esperados):\n",
    "    \"\"\"Valida que las columnas tengan los tipos de datos esperados.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a validar\n",
    "        tipos_esperados: Diccionario con columnas y sus tipos esperados\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de la validación\n",
    "    \"\"\"\n",
    "    # Verificamos que todas las columnas existan\n",
    "    columnas_faltantes = [col for col in tipos_esperados.keys() if col not in df.columns]\n",
    "    if columnas_faltantes:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Columnas faltantes: {', '.join(columnas_faltantes)}\"\n",
    "        }\n",
    "    \n",
    "    # Verificamos los tipos de datos\n",
    "    tipos_incorrectos = {}\n",
    "    for columna, tipo_esperado in tipos_esperados.items():\n",
    "        tipo_actual = df[columna].dtype\n",
    "        if not pd.api.types.is_dtype_equal(tipo_actual, tipo_esperado):\n",
    "            # Para tipos numéricos, verificamos si podemos convertir sin pérdida de información\n",
    "            if pd.api.types.is_numeric_dtype(tipo_esperado) and pd.api.types.is_numeric_dtype(tipo_actual):\n",
    "                continue\n",
    "            \n",
    "            # Para fechas, verificamos si podemos convertir\n",
    "            if tipo_esperado == 'datetime64[ns]' and pd.api.types.is_string_dtype(tipo_actual):\n",
    "                try:\n",
    "                    pd.to_datetime(df[columna])\n",
    "                    continue\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            tipos_incorrectos[columna] = {'esperado': tipo_esperado, 'actual': str(tipo_actual)}\n",
    "    \n",
    "    if tipos_incorrectos:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Tipos de datos incorrectos en {len(tipos_incorrectos)} columnas\",\n",
    "            'detalle': tipos_incorrectos\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'valido': True,\n",
    "        'mensaje': \"Todos los tipos de datos son correctos\"\n",
    "    }\n",
    "\n",
    "def validar_rango_valores(df, rangos):\n",
    "    \"\"\"Valida que los valores estén dentro de los rangos especificados.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a validar\n",
    "        rangos: Diccionario con columnas y sus rangos (min, max)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con resultados de la validación\n",
    "    \"\"\"\n",
    "    # Verificamos que todas las columnas existan\n",
    "    columnas_faltantes = [col for col in rangos.keys() if col not in df.columns]\n",
    "    if columnas_faltantes:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Columnas faltantes: {', '.join(columnas_faltantes)}\"\n",
    "        }\n",
    "    \n",
    "    # Verificamos los rangos\n",
    "    fuera_de_rango = {}\n",
    "    for columna, (min_val, max_val) in rangos.items():\n",
    "        # Verificamos mínimo\n",
    "        if min_val is not None:\n",
    "            valores_bajo_minimo = df[df[columna] < min_val]\n",
    "            if not valores_bajo_minimo.empty:\n",
    "                if columna not in fuera_de_rango:\n",
    "                    fuera_de_rango[columna] = {}\n",
    "                fuera_de_rango[columna]['bajo_minimo'] = {\n",
    "                    'cantidad': len(valores_bajo_minimo),\n",
    "                    'minimo_esperado': min_val,\n",
    "                    'valor_minimo_encontrado': float(valores_bajo_minimo[columna].min())\n",
    "                }\n",
    "        \n",
    "        # Verificamos máximo\n",
    "        if max_val is not None:\n",
    "            valores_sobre_maximo = df[df[columna] > max_val]\n",
    "            if not valores_sobre_maximo.empty:\n",
    "                if columna not in fuera_de_rango:\n",
    "                    fuera_de_rango[columna] = {}\n",
    "                fuera_de_rango[columna]['sobre_maximo'] = {\n",
    "                    'cantidad': len(valores_sobre_maximo),\n",
    "                    'maximo_esperado': max_val,\n",
    "                    'valor_maximo_encontrado': float(valores_sobre_maximo[columna].max())\n",
    "                }\n",
    "    \n",
    "    if fuera_de_rango:\n",
    "        return {\n",
    "            'valido': False,\n",
    "            'error': f\"Valores fuera de rango en {len(fuera_de_rango)} columnas\",\n",
    "            'detalle': fuera_de_rango\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'valido': True,\n",
    "        'mensaje': \"Todos los valores están dentro de los rangos especificados\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: Creación de Tests para Funciones de Procesamiento\n",
    "\n",
    "Ahora que tenemos nuestras funciones de procesamiento, vamos a crear tests para verificar que funcionan correctamente. Estos tests estarán en el archivo `tests/test_processing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../tests/test_processing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../tests/test_processing.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Añadimos el directorio raíz al path para poder importar los módulos\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from utils.data_processing import calcular_metricas_ventas, categorizar_productos_por_precio, calcular_tendencia_ventas\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas_sample():\n",
    "    \"\"\"Fixture que crea un pequeño DataFrame de muestra para testing.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas_completo():\n",
    "    \"\"\"Fixture que carga el dataset completo de ventas.\"\"\"\n",
    "    return pd.read_csv(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'ventas_productos.csv'))\n",
    "\n",
    "def test_calcular_metricas_ventas(df_ventas_sample):\n",
    "    \"\"\"Test para la función de cálculo de métricas de ventas.\"\"\"\n",
    "    metricas = calcular_metricas_ventas(df_ventas_sample)\n",
    "    \n",
    "    # Verificamos que todas las métricas esperadas estén presentes\n",
    "    assert set(metricas.keys()) == {'total_ventas', 'promedio_venta', 'total_productos_vendidos', \n",
    "                                    'precio_promedio', 'descuento_promedio', 'ahorro_total'}\n",
    "    \n",
    "    # Verificamos algunos cálculos específicos\n",
    "    assert metricas['total_ventas'] == pytest.approx(1516.94, 0.01)\n",
    "    assert metricas['total_productos_vendidos'] == 6\n",
    "    assert metricas['precio_promedio'] == pytest.approx(403.32, 0.01)\n",
    "\n",
    "def test_calcular_metricas_ventas_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para la función de cálculo de métricas con el dataset completo.\"\"\"\n",
    "    metricas = calcular_metricas_ventas(df_ventas_completo)\n",
    "    \n",
    "    # Verificamos que todas las métricas sean números válidos\n",
    "    for metrica, valor in metricas.items():\n",
    "        assert isinstance(valor, (int, float))\n",
    "        assert not np.isnan(valor)\n",
    "        assert not np.isinf(valor)\n",
    "\n",
    "def test_categorizar_productos_por_precio(df_ventas_sample):\n",
    "    \"\"\"Test para la función de categorización de productos por precio.\"\"\"\n",
    "    df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\n",
    "    \n",
    "    # Verificamos que se haya añadido la columna de categoría de precio\n",
    "    assert 'categoria_precio' in df_categorizado.columns\n",
    "    \n",
    "    # Verificamos que las categorías sean correctas\n",
    "    assert df_categorizado.loc[0, 'categoria_precio'] == 'Lujo'  # Laptop HP: 899.99\n",
    "    assert df_categorizado.loc[1, 'categoria_precio'] == 'Premium'  # Monitor Dell: 249.99\n",
    "    assert df_categorizado.loc[2, 'categoria_precio'] == 'Estándar'  # Teclado Logitech: 59.99\n",
    "    \n",
    "    # Verificamos que el DataFrame original no se haya modificado\n",
    "    assert 'categoria_precio' not in df_ventas_sample.columns\n",
    "\n",
    "def test_categorizar_productos_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para la función de categorización con el dataset completo.\"\"\"\n",
    "    df_categorizado = categorizar_productos_por_precio(df_ventas_completo)\n",
    "    \n",
    "    # Verificamos que se haya añadido la columna de categoría de precio\n",
    "    assert 'categoria_precio' in df_categorizado.columns\n",
    "    \n",
    "    # Verificamos que todas las filas tengan una categoría válida\n",
    "    categorias_validas = {'Económico', 'Estándar', 'Premium', 'Lujo', 'Sin categoría'}\n",
    "    assert set(df_categorizado['categoria_precio'].unique()).issubset(categorias_validas)\n",
    "    \n",
    "    # Verificamos que haya al menos un producto en cada categoría principal\n",
    "    for categoria in ['Económico', 'Estándar', 'Premium', 'Lujo']:\n",
    "        assert categoria in df_categorizado['categoria_precio'].values, f\"No hay productos en la categoría {categoria}\"\n",
    "\n",
    "def test_calcular_tendencia_ventas(df_ventas_sample):\n",
    "    \"\"\"Test para la función de cálculo de tendencia de ventas.\"\"\"\n",
    "    tendencia = calcular_tendencia_ventas(df_ventas_sample)\n",
    "    \n",
    "    # Verificamos que el DataFrame tenga las columnas esperadas\n",
    "    assert set(tendencia.columns) == {'mes', 'total', 'variacion_porcentual'}\n",
    "    \n",
    "    # Verificamos que solo haya un mes (ya que todas las fechas son de enero 2023)\n",
    "    assert len(tendencia) == 1\n",
    "    assert tendencia.iloc[0]['mes'] == '2023-01'\n",
    "    assert tendencia.iloc[0]['total'] == pytest.approx(1516.94, 0.01)\n",
    "    assert np.isnan(tendencia.iloc[0]['variacion_porcentual'])  # No hay mes anterior para comparar\n",
    "\n",
    "def test_calcular_tendencia_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para la función de tendencia con el dataset completo.\"\"\"\n",
    "    tendencia = calcular_tendencia_ventas(df_ventas_completo)\n",
    "    \n",
    "    # Verificamos que el DataFrame tenga las columnas esperadas\n",
    "    assert set(tendencia.columns) == {'mes', 'total', 'variacion_porcentual'}\n",
    "    \n",
    "    # Verificamos que haya al menos un mes\n",
    "    assert len(tendencia) > 0\n",
    "    \n",
    "    # Verificamos que los meses estén en formato YYYY-MM\n",
    "    import re\n",
    "    for mes in tendencia['mes']:\n",
    "        assert re.match(r'^\\d{4}-\\d{2}$', mes), f\"El mes {mes} no tiene el formato esperado (YYYY-MM)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Creación de Tests para Funciones de Validación\n",
    "\n",
    "Ahora vamos a crear tests para nuestras funciones de validación de datos. Estos tests estarán en el archivo `tests/test_validation.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../tests/test_validation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../tests/test_validation.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Añadimos el directorio raíz al path para poder importar los módulos\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from utils.data_validation import validar_completitud, validar_tipos_datos, validar_rango_valores\n",
    "\n",
    "@pytest.fixture\n",
    "def df_valido():\n",
    "    \"\"\"Fixture que crea un DataFrame válido para testing.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_con_nulos():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores nulos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', None, '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', None],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, None],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_tipos_incorrectos():\n",
    "    \"\"\"Fixture que crea un DataFrame con tipos de datos incorrectos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': ['899.99', '249.99', '59.99'],  # Strings en lugar de float\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_fuera_de_rango():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores fuera de rango.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, -3],  # Valor negativo\n",
    "        'descuento': [0.05, 0.00, 1.5],  # Descuento mayor a 1 (100%)\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas_completo():\n",
    "    \"\"\"Fixture que carga el dataset completo de ventas.\"\"\"\n",
    "    return pd.read_csv(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'ventas_productos.csv'))\n",
    "\n",
    "def test_validar_completitud_sin_nulos(df_valido):\n",
    "    \"\"\"Test para validar completitud en un DataFrame sin valores nulos.\"\"\"\n",
    "    resultado = validar_completitud(df_valido)\n",
    "    assert resultado['valido'] is True\n",
    "    assert 'mensaje' in resultado\n",
    "\n",
    "def test_validar_completitud_con_nulos(df_con_nulos):\n",
    "    \"\"\"Test para validar completitud en un DataFrame con valores nulos.\"\"\"\n",
    "    resultado = validar_completitud(df_con_nulos)\n",
    "    assert resultado['valido'] is False\n",
    "    assert 'error' in resultado\n",
    "    assert 'detalle' in resultado\n",
    "    assert resultado['detalle']['fecha'] == 1\n",
    "    assert resultado['detalle']['categoria'] == 1\n",
    "    assert resultado['detalle']['cantidad'] == 1\n",
    "\n",
    "def test_validar_completitud_columnas_especificas(df_con_nulos):\n",
    "    \"\"\"Test para validar completitud solo en columnas específicas.\"\"\"\n",
    "    # Validamos solo columnas que no tienen nulos\n",
    "    resultado = validar_completitud(df_con_nulos, ['id', 'producto', 'precio', 'descuento', 'total'])\n",
    "    assert resultado['valido'] is True\n",
    "    \n",
    "    # Validamos una columna que tiene nulos\n",
    "    resultado = validar_completitud(df_con_nulos, ['id', 'fecha'])\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['detalle']['fecha'] == 1\n",
    "\n",
    "def test_validar_completitud_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para validar completitud en el dataset completo.\"\"\"\n",
    "    resultado = validar_completitud(df_ventas_completo)\n",
    "    assert resultado['valido'] is True, \"El dataset completo no debería tener valores nulos\"\n",
    "\n",
    "def test_validar_tipos_datos_correctos(df_valido):\n",
    "    \"\"\"Test para validar tipos de datos correctos.\"\"\"\n",
    "    tipos_esperados = {\n",
    "        'id': 'int64',\n",
    "        'precio': 'float64',\n",
    "        'cantidad': 'int64',\n",
    "        'descuento': 'float64',\n",
    "        'total': 'float64'\n",
    "    }\n",
    "    resultado = validar_tipos_datos(df_valido, tipos_esperados)\n",
    "    assert resultado['valido'] is True\n",
    "\n",
    "def test_validar_tipos_datos_incorrectos(df_tipos_incorrectos):\n",
    "    \"\"\"Test para validar tipos de datos incorrectos.\"\"\"\n",
    "    tipos_esperados = {\n",
    "        'id': 'int64',\n",
    "        'precio': 'float64',  # En df_tipos_incorrectos, precio es string\n",
    "        'cantidad': 'int64',\n",
    "        'descuento': 'float64',\n",
    "        'total': 'float64'\n",
    "    }\n",
    "    resultado = validar_tipos_datos(df_tipos_incorrectos, tipos_esperados)\n",
    "    assert resultado['valido'] is False\n",
    "    assert 'precio' in resultado['detalle']\n",
    "\n",
    "def test_validar_tipos_datos_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para validar tipos de datos en el dataset completo.\"\"\"\n",
    "    tipos_esperados = {\n",
    "        'id': 'int64',\n",
    "        'fecha': 'object',  # Las fechas se cargan como strings (object)\n",
    "        'producto': 'object',\n",
    "        'categoria': 'object',\n",
    "        'precio': 'float64',\n",
    "        'cantidad': 'int64',\n",
    "        'descuento': 'float64',\n",
    "        'total': 'float64'\n",
    "    }\n",
    "    resultado = validar_tipos_datos(df_ventas_completo, tipos_esperados)\n",
    "    assert resultado['valido'] is True, \"Los tipos de datos en el dataset completo deberían ser correctos\"\n",
    "\n",
    "def test_validar_rango_valores_dentro_de_rango(df_valido):\n",
    "    \"\"\"Test para validar rangos de valores dentro de los límites.\"\"\"\n",
    "    rangos = {\n",
    "        'precio': (0, 1000),\n",
    "        'cantidad': (0, 10),\n",
    "        'descuento': (0, 1),\n",
    "        'total': (0, 1000)\n",
    "    }\n",
    "    resultado = validar_rango_valores(df_valido, rangos)\n",
    "    assert resultado['valido'] is True\n",
    "\n",
    "def test_validar_rango_valores_fuera_de_rango(df_fuera_de_rango):\n",
    "    \"\"\"Test para validar rangos de valores fuera de los límites.\"\"\"\n",
    "    rangos = {\n",
    "        'precio': (0, 1000),\n",
    "        'cantidad': (0, 10),  # En df_fuera_de_rango, hay un valor negativo\n",
    "        'descuento': (0, 1),  # En df_fuera_de_rango, hay un descuento > 1\n",
    "        'total': (0, 1000)\n",
    "    }\n",
    "    resultado = validar_rango_valores(df_fuera_de_rango, rangos)\n",
    "    assert resultado['valido'] is False\n",
    "    assert 'cantidad' in resultado['detalle']\n",
    "    assert 'descuento' in resultado['detalle']\n",
    "    assert 'bajo_minimo' in resultado['detalle']['cantidad']\n",
    "    assert 'sobre_maximo' in resultado['detalle']['descuento']\n",
    "\n",
    "def test_validar_rango_valores_dataset_completo(df_ventas_completo):\n",
    "    \"\"\"Test para validar rangos de valores en el dataset completo.\"\"\"\n",
    "    rangos = {\n",
    "        'precio': (0, 1000),\n",
    "        'cantidad': (0, 10),\n",
    "        'descuento': (0, 1),\n",
    "        'total': (0, 1000)\n",
    "    }\n",
    "    resultado = validar_rango_valores(df_ventas_completo, rangos)\n",
    "    assert resultado['valido'] is True, \"Todos los valores en el dataset completo deberían estar dentro de los rangos especificados\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 8: Ejecución de Tests\n",
    "\n",
    "Ahora que tenemos nuestras funciones y tests, vamos a ejecutar los tests para verificar que todo funciona correctamente.\n",
    "\n",
    "Primero, vamos a ejecutar los tests de procesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.9, pytest-8.3.5, pluggy-1.5.0 -- c:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.9.0, cov-6.1.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 6 items\n",
      "\n",
      "tests\\test_processing.py::test_calcular_metricas_ventas \u001b[32mPASSED\u001b[0m\u001b[32m           [ 16%]\u001b[0m\n",
      "tests\\test_processing.py::test_calcular_metricas_ventas_dataset_completo \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests\\test_processing.py::test_categorizar_productos_por_precio \u001b[31mFAILED\u001b[0m\u001b[31m   [ 50%]\u001b[0m\n",
      "tests\\test_processing.py::test_categorizar_productos_dataset_completo \u001b[32mPASSED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests\\test_processing.py::test_calcular_tendencia_ventas \u001b[32mPASSED\u001b[0m\u001b[31m          [ 83%]\u001b[0m\n",
      "tests\\test_processing.py::test_calcular_tendencia_dataset_completo \u001b[32mPASSED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________ test_calcular_metricas_ventas_dataset_completo ________________\u001b[0m\n",
      "\n",
      "df_ventas_completo =     id       fecha                producto  ... cantidad  descuento   total\n",
      "0    1  2023-01-05               Laptop HP...1       0.00  249.99\n",
      "19  20  2023-04-10          Cámara Digital  ...        1       0.15  339.99\n",
      "\n",
      "[20 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_calcular_metricas_ventas_dataset_completo\u001b[39;49;00m(df_ventas_completo):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de cálculo de métricas con el dataset completo.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        metricas = calcular_metricas_ventas(df_ventas_completo)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que todas las métricas sean números válidos\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m metrica, valor \u001b[95min\u001b[39;49;00m metricas.items():\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(valor, (\u001b[96mint\u001b[39;49;00m, \u001b[96mfloat\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +  where False = isinstance(np.int64(45), (<class 'int'>, <class 'float'>))\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_processing.py\u001b[0m:51: AssertionError\n",
      "\u001b[31m\u001b[1m____________________ test_categorizar_productos_por_precio ____________________\u001b[0m\n",
      "\n",
      "df_ventas_sample =    id       fecha          producto  ... cantidad  descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1...        2       0.00  499.98\n",
      "2   3  2023-01-15  Teclado Logitech  ...        3       0.10  161.97\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_categorizar_productos_por_precio\u001b[39;49;00m(df_ventas_sample):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de categorización de productos por precio.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que se haya añadido la columna de categoría de precio\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m df_categorizado.columns\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que las categorías sean correctas\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m0\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mLujo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Laptop HP: 899.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mPremium\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Monitor Dell: 249.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'Lujo' == 'Premium'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         - Premium\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + Lujo\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_processing.py\u001b[0m:64: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_processing.py::\u001b[1mtest_calcular_metricas_ventas_dataset_completo\u001b[0m - AssertionError: assert False\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_processing.py::\u001b[1mtest_categorizar_productos_por_precio\u001b[0m - AssertionError: assert 'Lujo' == 'Premium'\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m4 passed\u001b[0m\u001b[31m in 1.98s\u001b[0m\u001b[31m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python -m pytest tests/test_processing.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a ejecutar los tests de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.9, pytest-8.3.5, pluggy-1.5.0 -- c:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.9.0, cov-6.1.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 10 items\n",
      "\n",
      "tests\\test_validation.py::test_validar_completitud_sin_nulos \u001b[32mPASSED\u001b[0m\u001b[32m      [ 10%]\u001b[0m\n",
      "tests\\test_validation.py::test_validar_completitud_con_nulos \u001b[32mPASSED\u001b[0m\u001b[32m      [ 20%]\u001b[0m\n",
      "tests\\test_validation.py::test_validar_completitud_columnas_especificas \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests\\test_validation.py::test_validar_completitud_dataset_completo \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests\\test_validation.py::test_validar_tipos_datos_correctos \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
      "tests\\test_validation.py::test_validar_tipos_datos_incorrectos \u001b[32mPASSED\u001b[0m\u001b[32m    [ 60%]\u001b[0m\n",
      "tests\\test_validation.py::test_validar_tipos_datos_dataset_completo \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests\\test_validation.py::test_validar_rango_valores_dentro_de_rango \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests\\test_validation.py::test_validar_rango_valores_fuera_de_rango \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests\\test_validation.py::test_validar_rango_valores_dataset_completo \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================= \u001b[32m\u001b[1m10 passed\u001b[0m\u001b[32m in 0.85s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python -m pytest tests/test_validation.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos ejecutar todos los tests a la vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.9, pytest-8.3.5, pluggy-1.5.0\n",
      "rootdir: c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.9.0, cov-6.1.0\n",
      "collected 46 items\n",
      "\n",
      "tests\\temp_test.py \u001b[31mF\u001b[0m\u001b[31m                                                     [  2%]\u001b[0m\n",
      "tests\\test_data_processing.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                        [  8%]\u001b[0m\n",
      "tests\\test_data_validation.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                    [ 23%]\u001b[0m\n",
      "tests\\test_fixture_scope.py \u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31m                                         [ 32%]\u001b[0m\n",
      "tests\\test_numpy_integration.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                       [ 36%]\u001b[0m\n",
      "tests\\test_pandas_integration.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                      [ 41%]\u001b[0m\n",
      "tests\\test_parametrized.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                       [ 56%]\u001b[0m\n",
      "tests\\test_processing.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                          [ 69%]\u001b[0m\n",
      "tests\\test_validation.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                      [ 91%]\u001b[0m\n",
      "tests\\test_with_fixtures.py \u001b[31mE\u001b[0m\u001b[31m                                            [ 93%]\u001b[0m\n",
      "tests\\test_with_markers.py \u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31m                                           [100%]\u001b[0m\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_1_con_session_fixture _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33msession\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_session\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=session)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m1\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:10: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=session)...\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_2_con_session_fixture _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33msession\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_session\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=session)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m1\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:10: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_1_con_function_fixture ________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mfunction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_function\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=function)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m0.5\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:19: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=function)...\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_2_con_function_fixture ________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mfunction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_function\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=function)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m0.5\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:19: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=function)...\n",
      "\u001b[31m\u001b[1m___________ ERROR at setup of test_calcular_ingresos_por_categoria ____________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Fixture que carga el dataset de ventas.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_fixtures.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m_________________ ERROR at setup of test_columnas_requeridas __________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_markers.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m__________________ ERROR at setup of test_calculo_intensivo ___________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_markers.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m_________________ ERROR at setup of test_valores_no_negativos _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_markers.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________ test_calcular_total_con_impuesto _______________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_calcular_total_con_impuesto\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Caso 1: Impuesto por defecto (16%)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m calcular_total_con_impuesto(\u001b[94m100\u001b[39;49;00m) == \u001b[94m116.0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 115.99999999999999 == 116.0\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 115.99999999999999 = calcular_total_con_impuesto(100)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\temp_test.py\u001b[0m:7: AssertionError\n",
      "\u001b[31m\u001b[1m____________________ test_categorizar_productos_por_precio ____________________\u001b[0m\n",
      "\n",
      "df_ventas_sample =    id       fecha          producto  ... cantidad  descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1...        2       0.00  499.98\n",
      "2   3  2023-01-15  Teclado Logitech  ...        3       0.10  161.97\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_categorizar_productos_por_precio\u001b[39;49;00m(df_ventas_sample):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de categorización de productos por precio.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que se haya añadido la columna de categoría de precio\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m df_categorizado.columns\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que las categorías sean correctas\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m0\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mLujo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Laptop HP: 899.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mPremium\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Monitor Dell: 249.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'Lujo' == 'Premium'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         - Premium\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + Lujo\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_data_processing.py\u001b[0m:43: AssertionError\n",
      "\u001b[31m\u001b[1m_______________ test_calcular_metricas_ventas_dataset_completo ________________\u001b[0m\n",
      "\n",
      "df_ventas_completo =     id       fecha                producto  ... cantidad  descuento   total\n",
      "0    1  2023-01-05               Laptop HP...1       0.00  249.99\n",
      "19  20  2023-04-10          Cámara Digital  ...        1       0.15  339.99\n",
      "\n",
      "[20 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_calcular_metricas_ventas_dataset_completo\u001b[39;49;00m(df_ventas_completo):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de cálculo de métricas con el dataset completo.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        metricas = calcular_metricas_ventas(df_ventas_completo)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que todas las métricas sean números válidos\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m metrica, valor \u001b[95min\u001b[39;49;00m metricas.items():\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(valor, (\u001b[96mint\u001b[39;49;00m, \u001b[96mfloat\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +  where False = isinstance(np.int64(45), (<class 'int'>, <class 'float'>))\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_processing.py\u001b[0m:51: AssertionError\n",
      "\u001b[31m\u001b[1m____________________ test_categorizar_productos_por_precio ____________________\u001b[0m\n",
      "\n",
      "df_ventas_sample =    id       fecha          producto  ... cantidad  descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1...        2       0.00  499.98\n",
      "2   3  2023-01-15  Teclado Logitech  ...        3       0.10  161.97\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_categorizar_productos_por_precio\u001b[39;49;00m(df_ventas_sample):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de categorización de productos por precio.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que se haya añadido la columna de categoría de precio\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m df_categorizado.columns\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que las categorías sean correctas\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m0\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mLujo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Laptop HP: 899.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mPremium\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Monitor Dell: 249.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'Lujo' == 'Premium'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         - Premium\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + Lujo\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_processing.py\u001b[0m:64: AssertionError\n",
      "\u001b[33m============================== warnings summary ===============================\u001b[0m\n",
      "tests\\test_with_markers.py:9\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:9: PytestUnknownMarkWarning: Unknown pytest.mark.rapido - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.rapido\n",
      "\n",
      "tests\\test_with_markers.py:16\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:16: PytestUnknownMarkWarning: Unknown pytest.mark.lento - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.lento\n",
      "\n",
      "tests\\test_with_markers.py:26\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:26: PytestUnknownMarkWarning: Unknown pytest.mark.validacion - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.validacion\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests\\temp_test.py::\u001b[1mtest_calcular_total_con_impuesto\u001b[0m - assert 115.99999999999999 == 116.0\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_data_processing.py::\u001b[1mtest_categorizar_productos_por_precio\u001b[0m - AssertionError: assert 'Lujo' == 'Premium'\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_processing.py::\u001b[1mtest_calcular_metricas_ventas_dataset_completo\u001b[0m - AssertionError: assert False\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_processing.py::\u001b[1mtest_categorizar_productos_por_precio\u001b[0m - AssertionError: assert 'Lujo' == 'Premium'\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_1_con_session_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_2_con_session_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_1_con_function_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_2_con_function_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_fixtures.py::\u001b[1mtest_calcular_ingresos_por_categoria\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_markers.py::\u001b[1mtest_columnas_requeridas\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_markers.py::\u001b[1mtest_calculo_intensivo\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_markers.py::\u001b[1mtest_valores_no_negativos\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31m============= \u001b[31m\u001b[1m4 failed\u001b[0m, \u001b[32m34 passed\u001b[0m, \u001b[33m3 warnings\u001b[0m, \u001b[31m\u001b[1m8 errors\u001b[0m\u001b[31m in 4.54s\u001b[0m\u001b[31m ==============\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python -m pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 9: Medición de Cobertura de Código\n",
    "\n",
    "Una métrica importante en testing es la cobertura de código, que mide qué porcentaje de nuestro código está siendo ejecutado por los tests. Vamos a medir la cobertura de nuestros tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.9, pytest-8.3.5, pluggy-1.5.0\n",
      "rootdir: c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.9.0, cov-6.1.0\n",
      "collected 46 items\n",
      "\n",
      "tests\\temp_test.py \u001b[31mF\u001b[0m\u001b[31m                                                     [  2%]\u001b[0m\n",
      "tests\\test_data_processing.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                        [  8%]\u001b[0m\n",
      "tests\\test_data_validation.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                    [ 23%]\u001b[0m\n",
      "tests\\test_fixture_scope.py \u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31m                                         [ 32%]\u001b[0m\n",
      "tests\\test_numpy_integration.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                       [ 36%]\u001b[0m\n",
      "tests\\test_pandas_integration.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                      [ 41%]\u001b[0m\n",
      "tests\\test_parametrized.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                       [ 56%]\u001b[0m\n",
      "tests\\test_processing.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                          [ 69%]\u001b[0m\n",
      "tests\\test_validation.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                      [ 91%]\u001b[0m\n",
      "tests\\test_with_fixtures.py \u001b[31mE\u001b[0m\u001b[31m                                            [ 93%]\u001b[0m\n",
      "tests\\test_with_markers.py \u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31m                                           [100%]\u001b[0m\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_1_con_session_fixture _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33msession\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_session\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=session)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m1\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:10: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=session)...\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_2_con_session_fixture _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33msession\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_session\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=session)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m1\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:10: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_1_con_function_fixture ________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mfunction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_function\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=function)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m0.5\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:19: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=function)...\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_2_con_function_fixture ________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mfunction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_function\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=function)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m0.5\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:19: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=function)...\n",
      "\u001b[31m\u001b[1m___________ ERROR at setup of test_calcular_ingresos_por_categoria ____________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Fixture que carga el dataset de ventas.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_fixtures.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m_________________ ERROR at setup of test_columnas_requeridas __________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_markers.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m__________________ ERROR at setup of test_calculo_intensivo ___________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_markers.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m_________________ ERROR at setup of test_valores_no_negativos _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_markers.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________ test_calcular_total_con_impuesto _______________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_calcular_total_con_impuesto\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Caso 1: Impuesto por defecto (16%)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m calcular_total_con_impuesto(\u001b[94m100\u001b[39;49;00m) == \u001b[94m116.0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 115.99999999999999 == 116.0\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 115.99999999999999 = calcular_total_con_impuesto(100)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\temp_test.py\u001b[0m:7: AssertionError\n",
      "\u001b[31m\u001b[1m____________________ test_categorizar_productos_por_precio ____________________\u001b[0m\n",
      "\n",
      "df_ventas_sample =    id       fecha          producto  ... cantidad  descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1...        2       0.00  499.98\n",
      "2   3  2023-01-15  Teclado Logitech  ...        3       0.10  161.97\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_categorizar_productos_por_precio\u001b[39;49;00m(df_ventas_sample):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de categorización de productos por precio.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que se haya añadido la columna de categoría de precio\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m df_categorizado.columns\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que las categorías sean correctas\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m0\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mLujo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Laptop HP: 899.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mPremium\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Monitor Dell: 249.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'Lujo' == 'Premium'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         - Premium\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + Lujo\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_data_processing.py\u001b[0m:43: AssertionError\n",
      "\u001b[31m\u001b[1m_______________ test_calcular_metricas_ventas_dataset_completo ________________\u001b[0m\n",
      "\n",
      "df_ventas_completo =     id       fecha                producto  ... cantidad  descuento   total\n",
      "0    1  2023-01-05               Laptop HP...1       0.00  249.99\n",
      "19  20  2023-04-10          Cámara Digital  ...        1       0.15  339.99\n",
      "\n",
      "[20 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_calcular_metricas_ventas_dataset_completo\u001b[39;49;00m(df_ventas_completo):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de cálculo de métricas con el dataset completo.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        metricas = calcular_metricas_ventas(df_ventas_completo)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que todas las métricas sean números válidos\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m metrica, valor \u001b[95min\u001b[39;49;00m metricas.items():\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(valor, (\u001b[96mint\u001b[39;49;00m, \u001b[96mfloat\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +  where False = isinstance(np.int64(45), (<class 'int'>, <class 'float'>))\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_processing.py\u001b[0m:51: AssertionError\n",
      "\u001b[31m\u001b[1m____________________ test_categorizar_productos_por_precio ____________________\u001b[0m\n",
      "\n",
      "df_ventas_sample =    id       fecha          producto  ... cantidad  descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1...        2       0.00  499.98\n",
      "2   3  2023-01-15  Teclado Logitech  ...        3       0.10  161.97\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_categorizar_productos_por_precio\u001b[39;49;00m(df_ventas_sample):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de categorización de productos por precio.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que se haya añadido la columna de categoría de precio\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m df_categorizado.columns\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que las categorías sean correctas\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m0\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mLujo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Laptop HP: 899.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mPremium\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Monitor Dell: 249.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'Lujo' == 'Premium'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         - Premium\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + Lujo\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_processing.py\u001b[0m:64: AssertionError\n",
      "\u001b[33m============================== warnings summary ===============================\u001b[0m\n",
      "tests\\test_with_markers.py:9\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:9: PytestUnknownMarkWarning: Unknown pytest.mark.rapido - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.rapido\n",
      "\n",
      "tests\\test_with_markers.py:16\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:16: PytestUnknownMarkWarning: Unknown pytest.mark.lento - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.lento\n",
      "\n",
      "tests\\test_with_markers.py:26\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:26: PytestUnknownMarkWarning: Unknown pytest.mark.validacion - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.validacion\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "=============================== tests coverage ================================\n",
      "_______________ coverage: platform win32, python 3.11.9-final-0 _______________\n",
      "\n",
      "Name                       Stmts   Miss  Cover\n",
      "----------------------------------------------\n",
      "utils\\__init__.py              2      0   100%\n",
      "utils\\data_processing.py      19      0   100%\n",
      "utils\\data_validation.py      55      9    84%\n",
      "----------------------------------------------\n",
      "TOTAL                         76      9    88%\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests\\temp_test.py::\u001b[1mtest_calcular_total_con_impuesto\u001b[0m - assert 115.99999999999999 == 116.0\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_data_processing.py::\u001b[1mtest_categorizar_productos_por_precio\u001b[0m - AssertionError: assert 'Lujo' == 'Premium'\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_processing.py::\u001b[1mtest_calcular_metricas_ventas_dataset_completo\u001b[0m - AssertionError: assert False\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_processing.py::\u001b[1mtest_categorizar_productos_por_precio\u001b[0m - AssertionError: assert 'Lujo' == 'Premium'\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_1_con_session_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_2_con_session_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_1_con_function_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_2_con_function_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_fixtures.py::\u001b[1mtest_calcular_ingresos_por_categoria\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_markers.py::\u001b[1mtest_columnas_requeridas\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_markers.py::\u001b[1mtest_calculo_intensivo\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_markers.py::\u001b[1mtest_valores_no_negativos\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31m============= \u001b[31m\u001b[1m4 failed\u001b[0m, \u001b[32m34 passed\u001b[0m, \u001b[33m3 warnings\u001b[0m, \u001b[31m\u001b[1m8 errors\u001b[0m\u001b[31m in 6.03s\u001b[0m\u001b[31m ==============\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python -m pytest --cov=utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener un informe más detallado de la cobertura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.9, pytest-8.3.5, pluggy-1.5.0\n",
      "rootdir: c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.9.0, cov-6.1.0\n",
      "collected 46 items\n",
      "\n",
      "tests\\temp_test.py \u001b[31mF\u001b[0m\u001b[31m                                                     [  2%]\u001b[0m\n",
      "tests\\test_data_processing.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                        [  8%]\u001b[0m\n",
      "tests\\test_data_validation.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                    [ 23%]\u001b[0m\n",
      "tests\\test_fixture_scope.py \u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31m                                         [ 32%]\u001b[0m\n",
      "tests\\test_numpy_integration.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                       [ 36%]\u001b[0m\n",
      "tests\\test_pandas_integration.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                      [ 41%]\u001b[0m\n",
      "tests\\test_parametrized.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                       [ 56%]\u001b[0m\n",
      "tests\\test_processing.py \u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                          [ 69%]\u001b[0m\n",
      "tests\\test_validation.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                      [ 91%]\u001b[0m\n",
      "tests\\test_with_fixtures.py \u001b[31mE\u001b[0m\u001b[31m                                            [ 93%]\u001b[0m\n",
      "tests\\test_with_markers.py \u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31m                                           [100%]\u001b[0m\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_1_con_session_fixture _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33msession\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_session\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=session)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m1\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:10: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=session)...\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_2_con_session_fixture _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33msession\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_session\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=session)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m1\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:10: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_1_con_function_fixture ________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mfunction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_function\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=function)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m0.5\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:19: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=function)...\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_2_con_function_fixture ________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mfunction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_function\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=function)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m0.5\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:19: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=function)...\n",
      "\u001b[31m\u001b[1m___________ ERROR at setup of test_calcular_ingresos_por_categoria ____________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Fixture que carga el dataset de ventas.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_fixtures.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m_________________ ERROR at setup of test_columnas_requeridas __________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_markers.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m__________________ ERROR at setup of test_calculo_intensivo ___________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_markers.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m_________________ ERROR at setup of test_valores_no_negativos _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_markers.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mc:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________ test_calcular_total_con_impuesto _______________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_calcular_total_con_impuesto\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Caso 1: Impuesto por defecto (16%)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m calcular_total_con_impuesto(\u001b[94m100\u001b[39;49;00m) == \u001b[94m116.0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 115.99999999999999 == 116.0\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 115.99999999999999 = calcular_total_con_impuesto(100)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\temp_test.py\u001b[0m:7: AssertionError\n",
      "\u001b[31m\u001b[1m____________________ test_categorizar_productos_por_precio ____________________\u001b[0m\n",
      "\n",
      "df_ventas_sample =    id       fecha          producto  ... cantidad  descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1...        2       0.00  499.98\n",
      "2   3  2023-01-15  Teclado Logitech  ...        3       0.10  161.97\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_categorizar_productos_por_precio\u001b[39;49;00m(df_ventas_sample):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de categorización de productos por precio.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que se haya añadido la columna de categoría de precio\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m df_categorizado.columns\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que las categorías sean correctas\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m0\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mLujo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Laptop HP: 899.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mPremium\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Monitor Dell: 249.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'Lujo' == 'Premium'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         - Premium\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + Lujo\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_data_processing.py\u001b[0m:43: AssertionError\n",
      "\u001b[31m\u001b[1m_______________ test_calcular_metricas_ventas_dataset_completo ________________\u001b[0m\n",
      "\n",
      "df_ventas_completo =     id       fecha                producto  ... cantidad  descuento   total\n",
      "0    1  2023-01-05               Laptop HP...1       0.00  249.99\n",
      "19  20  2023-04-10          Cámara Digital  ...        1       0.15  339.99\n",
      "\n",
      "[20 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_calcular_metricas_ventas_dataset_completo\u001b[39;49;00m(df_ventas_completo):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de cálculo de métricas con el dataset completo.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        metricas = calcular_metricas_ventas(df_ventas_completo)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que todas las métricas sean números válidos\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m metrica, valor \u001b[95min\u001b[39;49;00m metricas.items():\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(valor, (\u001b[96mint\u001b[39;49;00m, \u001b[96mfloat\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +  where False = isinstance(np.int64(45), (<class 'int'>, <class 'float'>))\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_processing.py\u001b[0m:51: AssertionError\n",
      "\u001b[31m\u001b[1m____________________ test_categorizar_productos_por_precio ____________________\u001b[0m\n",
      "\n",
      "df_ventas_sample =    id       fecha          producto  ... cantidad  descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1...        2       0.00  499.98\n",
      "2   3  2023-01-15  Teclado Logitech  ...        3       0.10  161.97\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_categorizar_productos_por_precio\u001b[39;49;00m(df_ventas_sample):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la función de categorización de productos por precio.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que se haya añadido la columna de categoría de precio\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m df_categorizado.columns\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que las categorías sean correctas\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m0\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mLujo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Laptop HP: 899.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mPremium\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Monitor Dell: 249.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'Lujo' == 'Premium'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         - Premium\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + Lujo\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_processing.py\u001b[0m:64: AssertionError\n",
      "\u001b[33m============================== warnings summary ===============================\u001b[0m\n",
      "tests\\test_with_markers.py:9\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:9: PytestUnknownMarkWarning: Unknown pytest.mark.rapido - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.rapido\n",
      "\n",
      "tests\\test_with_markers.py:16\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:16: PytestUnknownMarkWarning: Unknown pytest.mark.lento - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.lento\n",
      "\n",
      "tests\\test_with_markers.py:26\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:26: PytestUnknownMarkWarning: Unknown pytest.mark.validacion - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.validacion\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "=============================== tests coverage ================================\n",
      "_______________ coverage: platform win32, python 3.11.9-final-0 _______________\n",
      "\n",
      "Name                       Stmts   Miss  Cover   Missing\n",
      "--------------------------------------------------------\n",
      "utils\\__init__.py              2      0   100%\n",
      "utils\\data_processing.py      19      0   100%\n",
      "utils\\data_validation.py      55      9    84%   20, 55, 67, 71-75, 104\n",
      "--------------------------------------------------------\n",
      "TOTAL                         76      9    88%\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests\\temp_test.py::\u001b[1mtest_calcular_total_con_impuesto\u001b[0m - assert 115.99999999999999 == 116.0\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_data_processing.py::\u001b[1mtest_categorizar_productos_por_precio\u001b[0m - AssertionError: assert 'Lujo' == 'Premium'\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_processing.py::\u001b[1mtest_calcular_metricas_ventas_dataset_completo\u001b[0m - AssertionError: assert False\n",
      "\u001b[31mFAILED\u001b[0m tests\\test_processing.py::\u001b[1mtest_categorizar_productos_por_precio\u001b[0m - AssertionError: assert 'Lujo' == 'Premium'\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_1_con_session_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_2_con_session_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_1_con_function_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_fixture_scope.py::\u001b[1mtest_2_con_function_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_fixtures.py::\u001b[1mtest_calcular_ingresos_por_categoria\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_markers.py::\u001b[1mtest_columnas_requeridas\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_markers.py::\u001b[1mtest_calculo_intensivo\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests\\test_with_markers.py::\u001b[1mtest_valores_no_negativos\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31m============= \u001b[31m\u001b[1m4 failed\u001b[0m, \u001b[32m34 passed\u001b[0m, \u001b[33m3 warnings\u001b[0m, \u001b[31m\u001b[1m8 errors\u001b[0m\u001b[31m in 5.92s\u001b[0m\u001b[31m ==============\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python -m pytest --cov=utils --cov-report=term-missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 10: Uso de Marcadores para Categorizar Tests\n",
    "\n",
    "Los marcadores nos permiten categorizar los tests y seleccionar subconjuntos específicos para ejecutar. Vamos a crear un nuevo archivo de tests con marcadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../tests/test_with_markers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../tests/test_with_markers.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Añadimos el directorio raíz al path para poder importar los módulos\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "@pytest.fixture\n",
    "def df_ventas():\n",
    "    \"\"\"Fixture que carga el dataset de ventas.\"\"\"\n",
    "    return pd.read_csv(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'ventas_productos.csv'))\n",
    "\n",
    "@pytest.mark.rapido\n",
    "def test_columnas_requeridas(df_ventas):\n",
    "    \"\"\"Test rápido que verifica que el DataFrame tenga las columnas requeridas.\"\"\"\n",
    "    columnas_requeridas = ['id', 'fecha', 'producto', 'categoria', 'precio', 'cantidad', 'descuento', 'total']\n",
    "    for columna in columnas_requeridas:\n",
    "        assert columna in df_ventas.columns, f\"La columna {columna} debería estar presente\"\n",
    "\n",
    "@pytest.mark.lento\n",
    "def test_calculo_intensivo(df_ventas):\n",
    "    \"\"\"Test lento que simula un cálculo intensivo.\"\"\"\n",
    "    # Simulamos un cálculo que toma tiempo\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Realizamos algún cálculo con el DataFrame\n",
    "    resultado = df_ventas.groupby(['categoria', 'fecha']).agg({'total': 'sum'}).reset_index()\n",
    "    assert not resultado.empty, \"El resultado no debería estar vacío\"\n",
    "\n",
    "@pytest.mark.validacion\n",
    "def test_valores_no_negativos(df_ventas):\n",
    "    \"\"\"Test que verifica que no haya valores negativos en columnas numéricas.\"\"\"\n",
    "    columnas_numericas = ['precio', 'cantidad', 'total']\n",
    "    for columna in columnas_numericas:\n",
    "        assert (df_ventas[columna] >= 0).all(), f\"No debería haber valores negativos en {columna}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar solo los tests rápidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.9, pytest-8.3.5, pluggy-1.5.0 -- c:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.9.0, cov-6.1.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items / 2 deselected / 1 selected\n",
      "\n",
      "tests\\test_with_markers.py::test_columnas_requeridas \u001b[32mPASSED\u001b[0m\u001b[33m              [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m============================== warnings summary ===============================\u001b[0m\n",
      "tests\\test_with_markers.py:16\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:16: PytestUnknownMarkWarning: Unknown pytest.mark.rapido - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.rapido\n",
      "\n",
      "tests\\test_with_markers.py:23\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:23: PytestUnknownMarkWarning: Unknown pytest.mark.lento - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.lento\n",
      "\n",
      "tests\\test_with_markers.py:33\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:33: PytestUnknownMarkWarning: Unknown pytest.mark.validacion - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.validacion\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m================= \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m2 deselected\u001b[0m, \u001b[33m\u001b[1m3 warnings\u001b[0m\u001b[33m in 0.75s\u001b[0m\u001b[33m =================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python -m pytest tests/test_with_markers.py -m rapido -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar solo los tests de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.9, pytest-8.3.5, pluggy-1.5.0 -- c:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.9.0, cov-6.1.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items / 2 deselected / 1 selected\n",
      "\n",
      "tests\\test_with_markers.py::test_valores_no_negativos \u001b[32mPASSED\u001b[0m\u001b[33m             [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m============================== warnings summary ===============================\u001b[0m\n",
      "tests\\test_with_markers.py:16\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:16: PytestUnknownMarkWarning: Unknown pytest.mark.rapido - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.rapido\n",
      "\n",
      "tests\\test_with_markers.py:23\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:23: PytestUnknownMarkWarning: Unknown pytest.mark.lento - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.lento\n",
      "\n",
      "tests\\test_with_markers.py:33\n",
      "  c:\\Users\\Abdon\\Documents\\GitHub\\DS102024\\4-DataEngineer\\PyTest\\tests\\test_with_markers.py:33: PytestUnknownMarkWarning: Unknown pytest.mark.validacion - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
      "    @pytest.mark.validacion\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m================= \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m2 deselected\u001b[0m, \u001b[33m\u001b[1m3 warnings\u001b[0m\u001b[33m in 0.82s\u001b[0m\u001b[33m =================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python -m pytest tests/test_with_markers.py -m validacion -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 11: Configuración de Pytest\n",
    "\n",
    "Podemos configurar pytest para personalizar su comportamiento. Esto se hace típicamente a través de un archivo `pytest.ini` o `conftest.py`. Vamos a crear un archivo `pytest.ini` básico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../pytest.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../pytest.ini\n",
    "[pytest]\n",
    "markers =\n",
    "    rapido: tests que se ejecutan rápidamente\n",
    "    lento: tests que toman más tiempo en ejecutarse\n",
    "    validacion: tests que validan la calidad de los datos\n",
    "\n",
    "testpaths = tests\n",
    "python_files = test_*.py\n",
    "python_classes = Test*\n",
    "python_functions = test_*\n",
    "\n",
    "# Opciones de verbosidad y formato de salida\n",
    "addopts = -v --no-header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 12: Creación de un Script para Ejecutar Tests\n",
    "\n",
    "Para facilitar la ejecución de tests, podemos crear un script que ejecute los tests y genere un informe de cobertura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../run_tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../run_tests.py\n",
    "#!/usr/bin/env python\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"Ejecuta los tests y genera un informe de cobertura.\"\"\"\n",
    "    print(\"Ejecutando tests...\")\n",
    "    result = subprocess.run([\"pytest\", \"--cov=utils\", \"--cov-report=term-missing\"], capture_output=True, text=True)\n",
    "    \n",
    "    print(\"\\nResultados de los tests:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.stderr:\n",
    "        print(\"\\nErrores:\")\n",
    "        print(result.stderr)\n",
    "    \n",
    "    return result.returncode\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cambiamos al directorio raíz del proyecto\n",
    "    os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "    \n",
    "    # Ejecutamos los tests\n",
    "    exit_code = run_tests()\n",
    "    \n",
    "    # Salimos con el código de retorno de pytest\n",
    "    sys.exit(exit_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el script ejecutable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"chmod\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!chmod +x ../run_tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y lo ejecutamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando tests...\n",
      "\n",
      "Resultados de los tests:\n",
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items\n",
      "\n",
      "tests/test_data_processing.py::test_calcular_metricas_ventas \u001b[32mPASSED\u001b[0m\u001b[32m      [  2%]\u001b[0m\n",
      "tests/test_data_processing.py::test_categorizar_productos_por_precio \u001b[31mFAILED\u001b[0m\u001b[31m [  4%]\u001b[0m\n",
      "tests/test_data_processing.py::test_calcular_tendencia_ventas \u001b[32mPASSED\u001b[0m\u001b[31m     [  6%]\u001b[0m\n",
      "tests/test_data_validation.py::test_validar_completitud_sin_nulos \u001b[32mPASSED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/test_data_validation.py::test_validar_completitud_con_nulos \u001b[32mPASSED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/test_data_validation.py::test_validar_completitud_columnas_especificas \u001b[32mPASSED\u001b[0m\u001b[31m [ 13%]\u001b[0m\n",
      "tests/test_data_validation.py::test_validar_tipos_datos_correctos \u001b[32mPASSED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
      "tests/test_data_validation.py::test_validar_tipos_datos_incorrectos \u001b[32mPASSED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/test_data_validation.py::test_validar_rango_valores_dentro_de_rango \u001b[32mPASSED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/test_data_validation.py::test_validar_rango_valores_fuera_de_rango \u001b[32mPASSED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/test_fixture_scope.py::test_1_con_session_fixture \u001b[31mERROR\u001b[0m\u001b[31m            [ 24%]\u001b[0m\n",
      "tests/test_fixture_scope.py::test_2_con_session_fixture \u001b[31mERROR\u001b[0m\u001b[31m            [ 26%]\u001b[0m\n",
      "tests/test_fixture_scope.py::test_1_con_function_fixture \u001b[31mERROR\u001b[0m\u001b[31m           [ 28%]\u001b[0m\n",
      "tests/test_fixture_scope.py::test_2_con_function_fixture \u001b[31mERROR\u001b[0m\u001b[31m           [ 31%]\u001b[0m\n",
      "tests/test_numpy_integration.py::test_normalizar_array \u001b[32mPASSED\u001b[0m\u001b[31m            [ 33%]\u001b[0m\n",
      "tests/test_numpy_integration.py::test_normalizar_array_constante \u001b[32mPASSED\u001b[0m\u001b[31m  [ 35%]\u001b[0m\n",
      "tests/test_pandas_integration.py::test_filtrar_por_categoria \u001b[32mPASSED\u001b[0m\u001b[31m      [ 37%]\u001b[0m\n",
      "tests/test_pandas_integration.py::test_filtrar_por_categoria_vacio \u001b[32mPASSED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/test_parametrized.py::test_validar_formato_fecha[2023-01-05-True] \u001b[32mPASSED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/test_parametrized.py::test_validar_formato_fecha[2023-1-5-False] \u001b[32mPASSED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/test_parametrized.py::test_validar_formato_fecha[01-05-2023-False] \u001b[32mPASSED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/test_parametrized.py::test_validar_formato_fecha[2023/01/05-False] \u001b[32mPASSED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/test_parametrized.py::test_validar_formato_fecha[20230105-False] \u001b[32mPASSED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/test_parametrized.py::test_validar_formato_fecha[2023-01-32-True] \u001b[32mPASSED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/test_parametrized.py::test_validar_formato_fecha[-False] \u001b[32mPASSED\u001b[0m\u001b[31m    [ 55%]\u001b[0m\n",
      "tests/test_processing.py::test_calcular_metricas_ventas \u001b[32mPASSED\u001b[0m\u001b[31m           [ 57%]\u001b[0m\n",
      "tests/test_processing.py::test_calcular_metricas_ventas_dataset_completo \u001b[31mFAILED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/test_processing.py::test_categorizar_productos_por_precio \u001b[31mFAILED\u001b[0m\u001b[31m   [ 62%]\u001b[0m\n",
      "tests/test_processing.py::test_categorizar_productos_dataset_completo \u001b[32mPASSED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/test_processing.py::test_calcular_tendencia_ventas \u001b[32mPASSED\u001b[0m\u001b[31m          [ 66%]\u001b[0m\n",
      "tests/test_processing.py::test_calcular_tendencia_dataset_completo \u001b[32mPASSED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/test_validation.py::test_validar_completitud_sin_nulos \u001b[32mPASSED\u001b[0m\u001b[31m      [ 71%]\u001b[0m\n",
      "tests/test_validation.py::test_validar_completitud_con_nulos \u001b[32mPASSED\u001b[0m\u001b[31m      [ 73%]\u001b[0m\n",
      "tests/test_validation.py::test_validar_completitud_columnas_especificas \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/test_validation.py::test_validar_completitud_dataset_completo \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/test_validation.py::test_validar_tipos_datos_correctos \u001b[32mPASSED\u001b[0m\u001b[31m      [ 80%]\u001b[0m\n",
      "tests/test_validation.py::test_validar_tipos_datos_incorrectos \u001b[32mPASSED\u001b[0m\u001b[31m    [ 82%]\u001b[0m\n",
      "tests/test_validation.py::test_validar_tipos_datos_dataset_completo \u001b[32mPASSED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/test_validation.py::test_validar_rango_valores_dentro_de_rango \u001b[32mPASSED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/test_validation.py::test_validar_rango_valores_fuera_de_rango \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/test_validation.py::test_validar_rango_valores_dataset_completo \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/test_with_fixtures.py::test_calcular_ingresos_por_categoria \u001b[31mERROR\u001b[0m\u001b[31m  [ 93%]\u001b[0m\n",
      "tests/test_with_markers.py::test_columnas_requeridas \u001b[32mPASSED\u001b[0m\u001b[31m              [ 95%]\u001b[0m\n",
      "tests/test_with_markers.py::test_calculo_intensivo \u001b[32mPASSED\u001b[0m\u001b[31m                [ 97%]\u001b[0m\n",
      "tests/test_with_markers.py::test_valores_no_negativos \u001b[32mPASSED\u001b[0m\u001b[31m             [100%]\u001b[0m\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_1_con_session_fixture _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33msession\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_session\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=session)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m1\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:10: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=session)...\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_2_con_session_fixture _________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33msession\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_session\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=session)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m1\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:10: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_1_con_function_fixture ________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mfunction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_function\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=function)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m0.5\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:19: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=function)...\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of test_2_con_function_fixture ________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mfunction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas_function\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mCargando dataset (scope=function)...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        time.sleep(\u001b[94m0.5\u001b[39;49;00m)  \u001b[90m# Simulamos una carga lenta\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       df = pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_fixture_scope.py\u001b[0m:19: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "---------------------------- Captured stdout setup ----------------------------\n",
      "\n",
      "Cargando dataset (scope=function)...\n",
      "\u001b[31m\u001b[1m___________ ERROR at setup of test_calcular_ingresos_por_categoria ____________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdf_ventas\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Fixture que carga el dataset de ventas.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m pd.read_csv(\u001b[33m'\u001b[39;49;00m\u001b[33m../data/ventas_productos.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_with_fixtures.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1026: in read_csv\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:620: in _read\n",
      "    \u001b[0mparser = TextFileReader(filepath_or_buffer, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1620: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m._engine = \u001b[96mself\u001b[39;49;00m._make_engine(f, \u001b[96mself\u001b[39;49;00m.engine)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m:1880: in _make_engine\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = '../data/ventas_productos.csv', mode = 'r'\n",
      "\n",
      "    \u001b[0m\u001b[37m@doc\u001b[39;49;00m(compression_options=_shared_docs[\u001b[33m\"\u001b[39;49;00m\u001b[33mcompression_options\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] % \u001b[33m\"\u001b[39;49;00m\u001b[33mpath_or_buf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_handle\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        path_or_buf: FilePath | BaseBuffer,\u001b[90m\u001b[39;49;00m\n",
      "        mode: \u001b[96mstr\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        *,\u001b[90m\u001b[39;49;00m\n",
      "        encoding: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        compression: CompressionOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        memory_map: \u001b[96mbool\u001b[39;49;00m = \u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        is_text: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        errors: \u001b[96mstr\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        storage_options: StorageOptions | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ) -> IOHandles[\u001b[96mstr\u001b[39;49;00m] | IOHandles[\u001b[96mbytes\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Get file handle for given path/buffer and mode.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    path_or_buf : str or file handle\u001b[39;49;00m\n",
      "    \u001b[33m        File path or object.\u001b[39;49;00m\n",
      "    \u001b[33m    mode : str\u001b[39;49;00m\n",
      "    \u001b[33m        Mode to open path_or_buf with.\u001b[39;49;00m\n",
      "    \u001b[33m    encoding : str or None\u001b[39;49;00m\n",
      "    \u001b[33m        Encoding to use.\u001b[39;49;00m\n",
      "    \u001b[33m    {compression_options}\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           May be a dict with key 'method' as compression mode\u001b[39;49;00m\n",
      "    \u001b[33m           and other keys as compression options if compression\u001b[39;49;00m\n",
      "    \u001b[33m           mode is 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m           Passing compression options as keys in dict is\u001b[39;49;00m\n",
      "    \u001b[33m           supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m        .. versionchanged:: 1.4.0 Zstandard support.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    memory_map : bool, default False\u001b[39;49;00m\n",
      "    \u001b[33m        See parsers._parser_params for more information. Only used by read_csv.\u001b[39;49;00m\n",
      "    \u001b[33m    is_text : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m        Whether the type of the content passed to the file/buffer is string or\u001b[39;49;00m\n",
      "    \u001b[33m        bytes. This is not the same as `\"b\" not in mode`. If a string content is\u001b[39;49;00m\n",
      "    \u001b[33m        passed to a binary file/buffer, a wrapper is inserted.\u001b[39;49;00m\n",
      "    \u001b[33m    errors : str, default 'strict'\u001b[39;49;00m\n",
      "    \u001b[33m        Specifies how encoding and decoding errors are to be handled.\u001b[39;49;00m\n",
      "    \u001b[33m        See the errors argument for :func:`open` for a full list\u001b[39;49;00m\n",
      "    \u001b[33m        of options.\u001b[39;49;00m\n",
      "    \u001b[33m    storage_options: StorageOptions = None\u001b[39;49;00m\n",
      "    \u001b[33m        Passed to _get_filepath_or_buffer\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns the dataclass IOHandles\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Windows does not default to utf-8. Set to utf-8 for a consistent behavior\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        encoding = encoding \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        errors = errors \u001b[95mor\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mstrict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# read_csv does not know whether the buffer is opened in binary/text mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m _is_binary_mode(path_or_buf, mode) \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode:\u001b[90m\u001b[39;49;00m\n",
      "            mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# validate encoding and errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        codecs.lookup(encoding)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(errors, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            codecs.lookup_error(errors)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# open URLs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ioargs = _get_filepath_or_buffer(\u001b[90m\u001b[39;49;00m\n",
      "            path_or_buf,\u001b[90m\u001b[39;49;00m\n",
      "            encoding=encoding,\u001b[90m\u001b[39;49;00m\n",
      "            compression=compression,\u001b[90m\u001b[39;49;00m\n",
      "            mode=mode,\u001b[90m\u001b[39;49;00m\n",
      "            storage_options=storage_options,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        handle = ioargs.filepath_or_buffer\u001b[90m\u001b[39;49;00m\n",
      "        handles: \u001b[96mlist\u001b[39;49;00m[BaseBuffer]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# memory mapping needs to be the first step\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# only used for read_csv\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        handle, memory_map, handles = _maybe_memory_map(handle, memory_map)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        is_path = \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        compression_args = \u001b[96mdict\u001b[39;49;00m(ioargs.compression)\u001b[90m\u001b[39;49;00m\n",
      "        compression = compression_args.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mmethod\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Only for write methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m mode \u001b[95mand\u001b[39;49;00m is_path:\u001b[90m\u001b[39;49;00m\n",
      "            check_parent_directory(\u001b[96mstr\u001b[39;49;00m(handle))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m compression:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression != \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries do not like an explicit text-mode\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode = ioargs.mode.replace(\u001b[33m\"\u001b[39;49;00m\u001b[33mt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# python-zstandard defaults to text mode, but we always expect\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# compression libraries to use binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ioargs.mode += \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# GZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mgzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Incompatible types in assignment (expression has type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(  \u001b[90m# type: ignore[assignment]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        filename=handle,\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handle = gzip.GzipFile(\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# No overload variant of \"GzipFile\" matches argument types\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle,  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                        **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# BZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mbz2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_bz2_file()(  \u001b[90m# type: ignore[call-overload]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **compression_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# ZIP Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = _BytesZipFile(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m handle.buffer.mode == \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    zip_names = handle.buffer.namelist()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(zip_names) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        handle = handle.buffer.open(zip_names.pop())\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m zip_names:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in ZIP file \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in ZIP file. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per ZIP: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mzip_names\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# TAR Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mtar\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                compression_args.setdefault(\u001b[33m\"\u001b[39;49;00m\u001b[33mmode\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ioargs.mode)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(name=handle, **compression_args)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# error: Argument \"fileobj\" to \"_BytesTarFile\" has incompatible\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# type \"BaseBuffer\"; expected \"Union[ReadBuffer[bytes],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# WriteBuffer[bytes], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    handle = _BytesTarFile(\u001b[90m\u001b[39;49;00m\n",
      "                        fileobj=handle, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    )\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, _BytesTarFile)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m handle.buffer.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "                    files = handle.buffer.getnames()\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(files) == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        file = handle.buffer.extractfile(files[\u001b[94m0\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94massert\u001b[39;49;00m file \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        handle = file\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m files:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mZero files found in TAR archive \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_or_buf\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33m\"\u001b[39;49;00m\u001b[33mMultiple files found in TAR archive. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mOnly one file per TAR archive: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfiles\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# XZ Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mxz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# error: Argument 1 to \"LZMAFile\" has incompatible type \"Union[str,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# BaseBuffer]\"; expected \"Optional[Union[Union[str, bytes, PathLike[str],\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# PathLike[bytes]], IO[bytes]], None]\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                handle = get_lzma_file()(\u001b[90m\u001b[39;49;00m\n",
      "                    handle, ioargs.mode, **compression_args  \u001b[90m# type: ignore[arg-type]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Zstd Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m compression == \u001b[33m\"\u001b[39;49;00m\u001b[33mzstd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                zstd = import_optional_dependency(\u001b[33m\"\u001b[39;49;00m\u001b[33mzstandard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mdctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdDecompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    open_args = {\u001b[33m\"\u001b[39;49;00m\u001b[33mcctx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: zstd.ZstdCompressor(**compression_args)}\u001b[90m\u001b[39;49;00m\n",
      "                handle = zstd.open(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    mode=ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    **open_args,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Unrecognized Compression\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUnrecognized compression type: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mcompression\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(msg)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            handles.append(handle)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(handle, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Check whether the filename is to be opened in binary mode.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m ioargs.encoding \u001b[95mand\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m ioargs.mode:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Encoding\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               handle = \u001b[96mopen\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                    handle,\u001b[90m\u001b[39;49;00m\n",
      "                    ioargs.mode,\u001b[90m\u001b[39;49;00m\n",
      "                    encoding=ioargs.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                    errors=errors,\u001b[90m\u001b[39;49;00m\n",
      "                    newline=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_productos.csv'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\Abdon\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bootcamp-ds-Fzf0xhKQ-py3.11\\Lib\\site-packages\\pandas\\io\\common.py\u001b[0m:873: FileNotFoundError\n",
      "================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________ test_categorizar_productos_por_precio ____________________\u001b[0m\n",
      "\n",
      "df_ventas_sample =    id       fecha          producto  ... cantidad  descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1...        2       0.00  499.98\n",
      "2   3  2023-01-15  Teclado Logitech  ...        3       0.10  161.97\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_categorizar_productos_por_precio\u001b[39;49;00m(df_ventas_sample):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la funciÃ³n de categorizaciÃ³n de productos por precio.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que se haya aÃ±adido la columna de categorÃ­a de precio\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m df_categorizado.columns\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que las categorÃ­as sean correctas\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m0\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mLujo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Laptop HP: 899.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mPremium\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Monitor Dell: 249.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'Lujo' == 'Premium'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         - Premium\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + Lujo\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_data_processing.py\u001b[0m:43: AssertionError\n",
      "\u001b[31m\u001b[1m_______________ test_calcular_metricas_ventas_dataset_completo ________________\u001b[0m\n",
      "\n",
      "df_ventas_completo =     id       fecha                producto  ... cantidad  descuento   total\n",
      "0    1  2023-01-05               Laptop HP...1       0.00  249.99\n",
      "19  20  2023-04-10          CÃ¡mara Digital  ...        1       0.15  339.99\n",
      "\n",
      "[20 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_calcular_metricas_ventas_dataset_completo\u001b[39;49;00m(df_ventas_completo):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la funciÃ³n de cÃ¡lculo de mÃ©tricas con el dataset completo.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        metricas = calcular_metricas_ventas(df_ventas_completo)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que todas las mÃ©tricas sean nÃºmeros vÃ¡lidos\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m metrica, valor \u001b[95min\u001b[39;49;00m metricas.items():\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(valor, (\u001b[96mint\u001b[39;49;00m, \u001b[96mfloat\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE            +  where False = isinstance(np.int64(45), (<class 'int'>, <class 'float'>))\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_processing.py\u001b[0m:51: AssertionError\n",
      "\u001b[31m\u001b[1m____________________ test_categorizar_productos_por_precio ____________________\u001b[0m\n",
      "\n",
      "df_ventas_sample =    id       fecha          producto  ... cantidad  descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1...        2       0.00  499.98\n",
      "2   3  2023-01-15  Teclado Logitech  ...        3       0.10  161.97\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_categorizar_productos_por_precio\u001b[39;49;00m(df_ventas_sample):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test para la funciÃ³n de categorizaciÃ³n de productos por precio.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        df_categorizado = categorizar_productos_por_precio(df_ventas_sample)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que se haya aÃ±adido la columna de categorÃ­a de precio\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m df_categorizado.columns\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Verificamos que las categorÃ­as sean correctas\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m0\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mLujo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Laptop HP: 899.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m df_categorizado.loc[\u001b[94m1\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcategoria_precio\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mPremium\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m  \u001b[90m# Monitor Dell: 249.99\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert 'Lujo' == 'Premium'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         \u001b[0m\n",
      "\u001b[1m\u001b[31mE         - Premium\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + Lujo\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_processing.py\u001b[0m:64: AssertionError\n",
      "=============================== tests coverage ================================\n",
      "_______________ coverage: platform win32, python 3.11.9-final-0 _______________\n",
      "\n",
      "Name                       Stmts   Miss  Cover   Missing\n",
      "--------------------------------------------------------\n",
      "utils\\__init__.py              2      0   100%\n",
      "utils\\data_processing.py      19      0   100%\n",
      "utils\\data_validation.py      55      9    84%   20, 55, 67, 71-75, 104\n",
      "--------------------------------------------------------\n",
      "TOTAL                         76      9    88%\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/test_data_processing.py::\u001b[1mtest_categorizar_productos_por_precio\u001b[0m - AssertionError: assert 'Lujo' == 'Premium'\n",
      "\u001b[31mFAILED\u001b[0m tests/test_processing.py::\u001b[1mtest_calcular_metricas_ventas_dataset_completo\u001b[0m - AssertionError: assert False\n",
      "\u001b[31mFAILED\u001b[0m tests/test_processing.py::\u001b[1mtest_categorizar_productos_por_precio\u001b[0m - AssertionError: assert 'Lujo' == 'Premium'\n",
      "\u001b[31mERROR\u001b[0m tests/test_fixture_scope.py::\u001b[1mtest_1_con_session_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests/test_fixture_scope.py::\u001b[1mtest_2_con_session_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests/test_fixture_scope.py::\u001b[1mtest_1_con_function_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests/test_fixture_scope.py::\u001b[1mtest_2_con_function_fixture\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31mERROR\u001b[0m tests/test_with_fixtures.py::\u001b[1mtest_calcular_ingresos_por_categoria\u001b[0m - FileNotFoundError: [Errno 2] No such file or directory: '../data/ventas_pro...\n",
      "\u001b[31m=================== \u001b[31m\u001b[1m3 failed\u001b[0m, \u001b[32m37 passed\u001b[0m, \u001b[31m\u001b[1m5 errors\u001b[0m\u001b[31m in 8.02s\u001b[0m\u001b[31m ====================\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python run_tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "En este notebook, hemos seguido un proceso paso a paso para implementar pytest en un proyecto de Data Engineering. Hemos visto cómo:\n",
    "\n",
    "1. Configurar el entorno y la estructura del proyecto\n",
    "2. Explorar el dataset para entender los datos\n",
    "3. Crear funciones de procesamiento y validación de datos\n",
    "4. Escribir tests para verificar estas funciones\n",
    "5. Ejecutar los tests y medir la cobertura de código\n",
    "6. Usar marcadores para categorizar y seleccionar tests\n",
    "7. Configurar pytest para personalizar su comportamiento\n",
    "8. Crear un script para facilitar la ejecución de tests\n",
    "\n",
    "Este enfoque sistemático nos permite asegurar la calidad de nuestro código y datos, lo que es fundamental en proyectos de Data Engineering donde la precisión y confiabilidad son críticas.\n",
    "\n",
    "En el siguiente notebook, veremos ejemplos más avanzados de pytest aplicados a escenarios específicos de Data Engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp-ds-Fzf0xhKQ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
